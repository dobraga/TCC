---
title: "Exemplo Predict Models"
output: html_notebook
---

```{r}
require(gbm)
set.seed(2108) # for reproducibility
```


```{r}
#
# A least squares regression example
#
# Simulate data
N <- 1000
X1 <- runif(N)
X2 <- 2 * runif(N)
X3 <- ordered(sample(letters[1:4], N, replace = TRUE), levels = letters[4:1])
X4 <- factor(sample(letters[1:6], N, replace = TRUE))
X5 <- factor(sample(letters[1:3], N, replace = TRUE))
X6 <- 3 * runif(N)
mu <- c(-1, 0, 1, 2)[as.numeric(X3)]
SNR <- 10 # signal-to-noise ratio
Y <- X1 ^ 1.5 + 2 * (X2 ^ 0.5) + mu
sigma <- sqrt(var(Y) / SNR)
Y <- Y + rnorm(N, 0, sigma)
X1[sample(1:N, size = 500)] <- NA # introduce some missing values
X4[sample(1:N, size = 300)] <- NA # introduce some missing values
data <- data.frame(Y, X1, X2, X3, X4, X5, X6)

data
```

```{r}
# Fit a GBM
gbm1 <- gbm(Y ~ ., data = data, var.monotone = c(0, 0, 0, 0, 0, 0),
            distribution = "gaussian", n.trees = 100, shrinkage = 0.1,
            interaction.depth = 3, bag.fraction = 0.5, train.fraction = 0.5,
            n.minobsinnode = 10, cv.folds = 5, keep.data = TRUE,
            verbose = FALSE, n.cores = 4)

gbm1
```

```{r}
# Check performance using the out-of-bag (OOB) error; the OOB error typically
# underestimates the optimal number of iterations
best.iter <- gbm.perf(gbm1, method = "OOB")
```

```{r}
# Check performance using the 50% heldout test set
best.iter <- gbm.perf(gbm1, method = "test")
```


```{r}
# Check performance using 5-fold cross-validation
best.iter <- gbm.perf(gbm1, method = "cv")
```


```{r}
# Plot relative influence of each variable
par(mfrow = c(1, 2))
a = summary(gbm1, n.trees = 1) # using first tree
a = summary(gbm1, n.trees = best.iter) # using estimated best number of trees
```


```{r}
# Compactly print the first and last trees for curiosity
print(pretty.gbm.tree(gbm1, i.tree = 1))
print(pretty.gbm.tree(gbm1, i.tree = gbm1$n.trees))
```
































